---
title: "Monitoring and Evaluation"
author: "chrispine buxtonre ooko"
date: '`r Sys.Date()`'
output: html_document
---

CHAPTER ONE: INTRODUCTION**

# 1.1 Background of the Study

Kenya continues to face persistent food insecurity, particularly among urban poor populations residing in informal settlements. According to humanitarian assessments, informal settlements in Nairobi such as Kibera, Mathare, Mukuru kwa Njenga, and Korogocho** experience chronic food insecurity driven by poverty, unemployment, high food prices, and recurrent shocks.

Humanitarian food security programs have increasingly integrated community-based real-time feedback mechanisms (RTFMs) to enhance accountability, responsiveness, and program quality. These mechanisms allow beneficiaries to provide immediate feedback through channels such as SMS, toll-free lines, suggestion boxes, and digital surveys.

Despite their adoption, limited empirical evaluation exists on the effectiveness, data quality, and operational challenges of these feedback systems within urban food security programming in Kenya. This study seeks to fill this gap using simulated (assimilated) data to demonstrate a robust Monitoring and Evaluation (M&E) framework.


# 1.2 Problem Statement**

While real-time feedback mechanisms are promoted as best practice in humanitarian accountability, their effectiveness in urban informal settlements remains uncertain. Challenges such as limited digital literacy, access barriers, delayed response to feedback, and data quality issues may undermine their intended purpose.

Without systematic monitoring and evaluation, humanitarian actors risk implementing feedback systems that are underutilized, poorly managed, or ineffective, thereby weakening accountability to affected populations. This project evaluates the performance of such systems in Nairobiâ€™s informal settlements using simulated data to model real-world humanitarian operations.



# 1.3 Project Objectives**

# General Objective

To monitor and evaluate the implementation and performance of a community based real-time feedback system integrated into humanitarian food security programs in urban informal settlements of Nairobi, Kenya.

# Specific Objectives

1. To assess the accessibility, functionality, and utilization of the real-time community feedback mechanism among targeted beneficiaries.
2. To analyze the quality, completeness, and timeliness of feedback data generated for effective monitoring and reporting.
3. To identify implementation challenges, best practices, and lessons learned in managing real-time feedback mechanisms.


# 1.4 Research Questions

1. How accessible and functional is the real-time feedback mechanism for beneficiaries in food-insecure urban settlements?
2. What is the quality and timeliness of feedback data generated through the system?
3. What operational challenges and best practices influence effective implementation?



# 1.5 Significance of the Study

* Supports NGOs and humanitarian agencies in improving accountability systems
* Strengthens MEAL system design and reporting
* Provides a replicable M&E framework using simulated data
* Useful for academic research, internships, and donor reporting

# METHODOLOGY

# Study Design

This study adopted a descriptive and analytical Monitoring and Evaluation (M&E) design. The design focused on assessing the implementation, functionality, and performance of a community-based real-time feedback mechanism (RTFM) integrated into a humanitarian food security program.

The study utilized simulated (assimilated) quantitative and qualitative data to model realistic humanitarian program operations. This approach enabled systematic analysis while avoiding the use of real beneficiary data, in line with ethical and academic requirements.


# Study Area**

The study was contextualized within urban informal settlements in Nairobi, Kenya, characterized by high population density, poverty, and food insecurity. The simulated data reflected conditions in the following settlements:

* Kibera
* Mathare
* Mukuru kwa Njenga
* Korogocho

These areas were selected due to their recurrent inclusion in humanitarian food security interventions.


# Target Population

The target population represented key stakeholders involved in the food security program, including:

* Beneficiaries receiving humanitarian food assistance
* Community mobilizers supporting feedback collection
* MEAL officers responsible for system management
* Program managers overseeing implementation


# Data Sources

The study relied exclusively on simulated data sources, designed to replicate real humanitarian program datasets.

| Data Type            | Description                                     |
| -------------------- | ----------------------------------------------- |
| Beneficiary registry | Simulated demographic and household data        |
| Feedback records     | Simulated SMS, hotline, and in-person feedback  |
| Response logs        | Simulated tracking of actions taken on feedback |
| Staff insights       | Simulated key informant interview summaries     |

No real personal or sensitive information was collected or analyzed.


# Sampling Technique and Sample Size

A simulated sample of 1000 beneficiaries was generated. The sample was stratified by settlement and gender to reflect equitable program coverage.

In addition, purposive sampling was applied to simulate:

* 5 MEAL officers
* 4 community mobilizers
* 3 program managers

This sampling approach aligns with standard humanitarian M&E practice.


# Data Collection Tools

The following simulated data collection tools were used:

* Kobo structured questionnaires
* Feedback categorization matrix
* MEAL response tracking template
* Simulated key informant interview guide

These tools were designed to reflect commonly used NGO MEAL systems.


# Study Variables and Indicators

The study variables were derived from the project objectives and accountability frameworks.

| Variable      | Indicator                                     |
| ------------- | --------------------------------------------- |
| Accessibility | % of beneficiaries aware of feedback channels |
| Utilization   | Feedback submissions per 1,000 beneficiaries  |
| Data Quality  | % of complete feedback records                |
| Timeliness    | Average feedback response time (days)         |
| Effectiveness | % of feedback resolved within SLA             |



# Data Analysis Procedures

Quantitative data are analyzed using descriptive statistics, including frequencies, percentages, and averages. Trend analysis is applied to examine feedback volume over time.

Qualitative feedback is analyzed using thematic analysis, with responses categorized into key themes such as food adequacy, targeting, and staff conduct.

Results are presented using tables, charts, and summary narratives.


# Ethical Considerations

The study adhered to ethical standards relevant to humanitarian research and academic work:

* Exclusive use of simulated (assimilated) data
* No collection of personal identifiers
* Alignment with humanitarian data protection principles
* No risk posed to individuals or communities

Ethical approval was not required due to the non-use of real human subjects.


# Methodological Limitations

* Simulated data may not capture all real-world complexities
* Findings are illustrative rather than generalizable
* Urban population mobility is approximated rather than observed

Despite these limitations, the methodology provides a robust framework for demonstrating effective M&E system evaluation.

# Data Analysis Plan

Data analysis is conducted using both quantitative and qualitative approaches, based on simulated datasets designed to reflect real humanitarian food security program data.

# Quantitative Data Analysis

Quantitative data are analyzed using descriptive statistical techniques. These included:

Frequencies and percentages to summarize beneficiary characteristics, awareness of feedback mechanisms, and utilization of feedback channels.

Measures of central tendency, such as averages, to assess response times and feedback resolution rates.

To examine system performance over time, trend analysis was conducted by aggregating feedback submissions on a monthly basis. This enabled assessment of changes in feedback volume and identification of periods with increased or decreased system utilization.

# Qualitative Data Analysis

Qualitative feedback data are analyzed using thematic analysis. Feedback narratives are reviewed, coded, and grouped into recurrent themes, including food quantity, distribution delays, staff conduct, and targeting concerns.

This approach allowed for systematic identification of key issues raised by beneficiaries and supported interpretation of quantitative findings.

# Data Visualization and Reporting

Findings were presented using visual and tabular formats to enhance interpretation and reporting. These included:

Bar charts and frequency tables to display feedback categories and channel usage.

Trend graphs to illustrate monthly feedback volumes.

Dashboards to summarize key performance indicators such as accessibility, timeliness, and feedback resolution rates.

All visualizations were designed to reflect standard MEAL reporting practices and to support evidence-based decision-making.

# Software and Tools

Data analysis and visualization were conducted using commonly applied tools in humanitarian M&E, including:

Microsoft Excel

R (for statistical analysis and visualization)




Import libraries

```{r setup, include=FALSE}

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}

# Load required libraries:

library(tidyverse)
library(lubridate)
library(janitor)
library(tidyverse)


```


```{r load-data}


## **2. Load the Simulated Dataset**

library(readxl)
Monitoring_and_Evaluation_project_data <- read_excel("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx")
Monitoring_and_Evaluation_project_data

library(readxl)

# List all sheets in the Excel file
excel_sheets("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx")

# Import "beneficiaries" sheet
beneficiaries <- read_excel("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx",
                            sheet = "Beneficiary.xlsx")
beneficiaries

# Import "feedback_txt"
feedback_txt <- read_excel("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx",
                     sheet = "feedback_txt")
feedback_txt

# Import "Feedback_log"
Feedback_log <- read_excel("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx",
                     sheet = "Feedback_log")
Feedback_log

# Import "response_tracker"
response_tracker <- read_excel("C:/Users/Administrator/Desktop/M&E/Monitoring_and_Evaluation_project_data.xlsx",
                     sheet = "response_tracker")
response_tracker

head(beneficiaries)


```


```{r}
head(Feedback_log)
```

```{r}
head(response_tracker)
```

Clean column names 
```{r}
beneficiaries <- beneficiaries %>% clean_names()
feedback_txt <- feedback_txt %>% clean_names()
Feedback_log <- Feedback_log %>% clean_names()
response_tracker <- response_tracker %>% clean_names()

```


Descriptive Statistics
Beneficiary Gender Distribution
```{r}
gender_summary <- beneficiaries %>%
  count(gender) %>%
  mutate(percentage = round((n / sum(n))*100,1))

gender_summary

```

Awareness of Feedback Channels
```{r}
awareness_summary <- beneficiaries %>%
  count(awareness_of_feedback) %>%
  mutate(percentage = round((n / sum(n))*100,1))

awareness_summary

```

Merge Feedback and Response Data

```{r}


feedback_data <- Feedback_log %>%
  left_join(response_tracker, by = "feedback_id","feedback_date",)

head(feedback_data)

```

Trend Analysis (Monthly Feedback Volume)
```{r}
colnames(feedback_data)


feedback_data <- feedback_data %>%
  mutate(month = floor_date(feedback_date.x, "month"))

monthly_trend <- feedback_data %>%
  group_by(month) %>%
  summarise(feedback_count = n())

monthly_trend

```
Timeliness Response 
```{r}
colnames(feedback_data)


response_summary <- feedback_data %>%
  summarise(
    average_response_days = round(mean(response_time_days, na.rm = TRUE),1),
    resolved_within_sla = round(mean(response_time_days <= 5, na.rm = TRUE)*100,1)
  )

response_summary

```

Feedback resolution rate
```{r}
resolution_summary <- feedback_data %>%
  count(resolution_status) %>%
  mutate(percentage = round((n / sum(n))*100,1))

resolution_summary

```

Thematic Analysis
```{r}

colnames(feedback_data)

theme_summary <- feedback_data %>%
  count(feedback_category) %>%
  mutate(percentage = round((n / sum(n))*100,1)) %>%
  arrange(desc(n))

theme_summary

```
Visualizations
Feedback Channels
```{r}
# Count number of feedback submissions per channel
channel_summary <- feedback_data %>%
  count(feedback_chanel) %>%                     # counts each channel
  mutate(percentage = round((n / sum(n)) * 100,1)) %>%   # calculate %
  arrange(desc(n))                                # sort descending

# View the summary
channel_summary


ggplot(channel_summary, aes(x = feedback_chanel, y = n)) +
  geom_col(fill="steelblue") +
  labs(title = "Feedback Channel Utilization", x = "Channel", y = "Count") +
  theme_minimal()

```

Monthly Feedback Trend
```{r}
ggplot(monthly_trend, aes(x = month, y = feedback_count)) +
  geom_line(color="darkgreen") +
  geom_point(color="darkgreen") +
  labs(title = "Monthly Feedback Volume", x = "Month", y = "Number of Feedbacks") +
  theme_minimal()

```

```{r}
kpis <- tibble(
  Indicator = c("Awareness of Feedback (%)",
                "Average Response Time (Days)",
                "Feedback Resolved Within SLA (%)"),
  Value = c(
    awareness_summary$percentage[awareness_summary$awareness_of_feedback=="Yes"],
    response_summary$average_response_days,
    response_summary$resolved_within_sla
  )
)

kpis

```

